# Video-Authoring-Tool

### TODO
1. GUI
2. part1 & part2 function

### Q & A
Q: Prof. Havaldar mentioned during the lecture (Nov 1, around 2:29:00) that students should “avoid using mp4 as an intermediate date format”. What does that mean?

A: One of the evaluations for the students is going to be synchronization of audio and video during playback. We need you to implement the synchronization for this! If they use an mp4 (generated by ffmpeg or something similar) and play the mp4 in a mp4 based player or mp4 library, the sync is already done by the libs. That is not what we want.

You can use rgb, or png or jpg or even read a frame from the avi. And then play the audio separately. You are free to use any libraries. As long as your do the the A/V sync by yourselves, that is OK


Q: On labeling the hyperlink, how dense do we want it to be? Will TA pick an arbitrary object bounding box and ask the student to match it in the 2nd video? In another word, are we expected to do a “dense matching”, where the code is designed to find the matched hyperlink for arbitrary objects in the 2nd video, by some machine learning (image captioning, natural language understanding, …)?

A: No - I don’t think we expect anything “smart” or “auto”. This is more like a software engineering authoring project using media. You ( the author ) creating the hyperlinked video will specify the area to be traced. Eg rect1 on frame 100, rect 2 on frame 300, rect3 on frame 400 - etc for one hyperlink (points to video and startframe on video). When you publish and load in your player, the defined area from frame 100 interpolated to rect2 in frame 200 interpolated to rect3 in frame 400 is the active area of the hyperlink - and clinking in that interpolated area in that frame segment should trigger the loading and playback of the hyperlinked video - which may also have hyperlinks defined in it. Additionally the hyperlink could also point to the same video at a different frame.


Q: An object usually appears in the video for many frames, and the object can be moving. Do we require the automatic tracking feature (tracking the actual object) to be implemented, or this depends on manual labeling (authoring)

A: Again no - no tracking, optical flow is expected. Some simple way to specify he regions being tracked (as example is in above description of mine) is needed - and the definition of that interpolated region should be respected in the player


Q: How to grade the project? creativity in GUI design? Engineering aspect: frame rate (30fps), etc.

A: Good questions. The creativity, etc. is not what we grade. Authoring Tool - Given that you have to define regions to trace/track - you will be graded on the availability of the functionality to do this while authoring. Implementations and exact workflow may vary, that is the students’ choice. As long as you can load a video, define multiple regions to track and author hyperlinks for such regions for different videos is what we are looking for.
Every authored file will have a corresponding published metadata file, whose format is their choice. We will author at least two - three videos each with one or two hyperlinks
Player - Start playing video evaluation ;
A/V sync at some point while playing the video;
Ensure that you can visualize somehow (cursor change, area color offset or something ) when a hyperlink becomes active;
Clicking on link should correctly load the hyperlink video at a certain defined frame and start playing the video. The time for change should not be too much ( a few 2 -4 seconds ).

### Deadline: 10:00 am PST on December 9